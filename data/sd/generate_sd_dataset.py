import numpy as np
import pandas as pd
import os

current_path = os.getcwd() # 获取当前路径 /home/data/xjn/23largest_baseline/LargeST/data/sd
print("current path:", current_path)
# ca_meta.csv [ID, Lat, Lng, District, County, Fwy, Lane, Type, Direction, ID2(0-8599)]
# 1. 处理源数据(节点数据)
ca_meta = pd.read_csv('./data/ca/ca_meta.csv')
sd_meta = ca_meta[ca_meta.District == 11] # select出指定行
sd_meta = sd_meta.reset_index() # 重置索引
sd_meta = sd_meta.drop(columns=['index']) # 去除index列
sd_meta.to_csv('sd_meta.csv', index=False) # 716*10的df
print(sd_meta[sd_meta.duplicated(subset=['Lat', 'Lng'])]) # Index: []# []中代码返回的是一个Series，其中为True的位置表示在'Lat'和'Lng'这两列上存在重复的行。
print("1. 已生成sd_meta.csv文件，716*10的df！")

# 2. 确认sd数据集中的节点编号
sd_meta_id2 = sd_meta.ID2.values.tolist() # 将sd_meta中的'ID2'列转换为一个列表（list）。
print(len(sd_meta_id2)) # len为716
print("2. 已确认sd的数据ID2编号6931-7646，是len为716的list！")

ca_rn_adj = np.load('./data/ca/ca_rn_adj.npy')
print(ca_rn_adj.shape) # (8600, 8600), 8600对应ca的总传感器数目
print("3. 已确认ca_data的邻接矩阵 8600*8600！")

sd_rn_adj = ca_rn_adj[sd_meta_id2] # 8k*8k, select 716*8k
sd_rn_adj = sd_rn_adj[:,sd_meta_id2]
print(sd_rn_adj, sd_rn_adj.shape) # 返回 716*716 的邻接矩阵
print("4. 已从ca的adj中挑出sd的adj，返回716*716的邻接矩阵！")

np.save('sd_rn_adj.npy', sd_rn_adj)


year = '2019'  # please specify the year, our experiments use 2019

sd_meta.ID = sd_meta.ID.astype(str) # 取出ID值, road编号，如1114091
sd_meta_id = sd_meta.ID.values.tolist() # 转字符串类型然后变list

ca_his = pd.read_hdf('./data/ca/ca_his_' + year +'.h5') # 读取的是没有null的新生成的ca.h5
'''
原始数据.h5
                     317802  312134  312133  313159  319767  319780  317830  314876  314886  314909  314780  ...  1201941  1221523  1221550  1221536  1221556  1219551  1202527  1202549  1219560  1202522  1202537
Time                                                                                                         ...                                                                                                   
2019-01-01 00:00:00    15.0    15.0    56.0    56.0    56.0    72.0    56.0    56.0    56.0    56.0    56.0  ...    100.0    103.0    101.0     92.0     77.0     41.0      0.0      NaN     31.0     55.0     52.0
2019-01-01 00:05:00    16.0    16.0    57.0    57.0    57.0    72.0    57.0    57.0    57.0    57.0    57.0  ...     99.0     91.0    108.0    103.0     85.0     45.0      0.0      NaN     21.0     58.0     52.0
2019-01-01 00:10:00    16.0    16.0    57.0    57.0    57.0    72.0    57.0    57.0    57.0    57.0    57.0  ...    118.0    111.0    105.0     83.0     66.0     69.0      0.0      NaN     25.0     80.0     70.0
2019-01-01 00:15:00    40.0    28.0    43.0    66.0    68.0    80.0    98.0    70.0    75.0   104.0    63.0  ...    180.0    138.0    134.0    104.0     80.0     80.0     80.0      NaN     26.0     94.0     98.0
2019-01-01 00:20:00    42.0    14.0    31.0    40.0    48.0    81.0    90.0    68.0    77.0    95.0    64.0  ...    209.0    190.0    181.0    130.0    107.0    165.0    130.0      NaN     39.0    137.0    123.0
...                     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...  ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...
2019-12-31 23:35:00    66.0    22.0    40.0    65.0    48.0    64.0    77.0    58.0    60.0    81.0    78.0  ...    164.0    191.0    163.0     93.0     94.0    112.0     99.0     91.0    111.0    112.0    101.0
2019-12-31 23:40:00    58.0    24.0    27.0    50.0    41.0    55.0    74.0    46.0    51.0    68.0    80.0  ...    164.0    189.0    142.0     94.0     95.0     86.0     82.0     73.0     86.0     88.0     82.0
2019-12-31 23:45:00    57.0    27.0    34.0    59.0    48.0    49.0    71.0    46.0    46.0    53.0    58.0  ...    132.0    169.0    143.0     91.0     94.0     81.0     83.0     78.0     28.0    102.0     94.0
2019-12-31 23:50:00    45.0    25.0    34.0    55.0    48.0    57.0    66.0    39.0    49.0    51.0    59.0  ...    134.0    177.0    124.0     75.0     79.0     80.0     75.0     70.0     23.0     62.0     64.0
2019-12-31 23:55:00    43.0    24.0    34.0    52.0    37.0    49.0    65.0    36.0    38.0    55.0    46.0  ...     98.0    153.0    105.0     75.0     70.0     68.0     56.0     57.0     20.0     50.0     48.0

[105120 rows x 8600 columns] <class 'pandas.core.frame.DataFrame'>
'''
sd_his = ca_his[sd_meta_id]
print(sd_his, type(sd_his))
'''
                     1114091  1118333  1118348  1114720  1118352  1118743  1120362  1118796  1118735  1118450  1114190  ...  1126526  1125829  1125348  1125353  1125359  1123287  1123276  1122394  1123261  1123256  1122412
Time                                                                                                                    ...                                                                                                   
2019-01-01 00:00:00     33.0     19.0     20.0     14.0     12.0     37.0     38.0     46.0     64.0     56.0     46.0  ...      5.0     24.0     21.0     22.0     50.0     10.0     40.0     12.0     12.0     24.0     34.0
2019-01-01 00:05:00     35.0     26.0     25.0     20.0     22.0     56.0     23.0     28.0     45.0     47.0     53.0  ...     11.0     22.0     23.0     28.0     50.0     19.0     45.0     19.0     11.0     25.0     36.0
2019-01-01 00:10:00     18.0     24.0     26.0     44.0     31.0     75.0     45.0     57.0     57.0     54.0     50.0  ...     11.0     32.0     47.0     43.0     79.0     23.0     48.0     20.0     15.0     33.0     42.0
2019-01-01 00:15:00     36.0     20.0     23.0     35.0     26.0     94.0     89.0     85.0     99.0     96.0     73.0  ...     11.0     41.0     26.0     28.0     45.0     15.0     41.0     16.0     14.0     22.0     42.0
2019-01-01 00:20:00     24.0     21.0     15.0     31.0     37.0    107.0    103.0    103.0     96.0    102.0     85.0  ...     10.0     23.0     20.0     21.0     43.0     12.0     37.0      8.0      9.0     21.0     36.0
...                      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...  ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...
2019-12-31 23:35:00     43.0     20.0     16.0     24.0     28.0     95.0    124.0     79.0     78.0     83.0    102.0  ...     13.0     46.0     39.0     41.0     68.0     24.0     51.0     31.0     21.0     44.0     54.0
2019-12-31 23:40:00     35.0     17.0     21.0     29.0     24.0     80.0    111.0     73.0     77.0     83.0     85.0  ...     15.0     43.0     49.0     52.0     83.0     41.0     63.0     38.0     30.0     54.0     56.0
2019-12-31 23:45:00     53.0     27.0     31.0     34.0     33.0     89.0    129.0     79.0     88.0     80.0     75.0  ...     18.0     50.0     42.0     45.0     73.0     21.0     47.0     19.0     15.0     29.0     40.0
2019-12-31 23:50:00     47.0     17.0     21.0     25.0     31.0     86.0    103.0     61.0     78.0     88.0     85.0  ...     12.0     31.0     32.0     30.0     59.0     16.0     40.0     16.0     10.0     19.0     34.0
2019-12-31 23:55:00     51.0     21.0     17.0     20.0     24.0     60.0     99.0     53.0     61.0     56.0     62.0  ...      7.0     36.0     32.0     32.0     64.0     20.0     45.0     20.0     19.0     19.0     36.0

[105120 rows x 716 columns] <class 'pandas.core.frame.DataFrame'>
'''


sd_his.to_hdf('sd_his_' + year + '.h5', key='t', mode='w')
print("5. 已获得sd_his_2019.h5文件, (105120, 716)!")



# code for checking adj stat
sd_rn_adj = np.load('sd_rn_adj.npy')
node_num = sd_rn_adj.shape[0]

print(sd_rn_adj[0,0])
sd_rn_adj[np.arange(node_num), np.arange(node_num)] = 0
print(sd_rn_adj[0,0])

print('edge number', np.count_nonzero(sd_rn_adj)) # 17319
print('node degree', np.mean(np.count_nonzero(sd_rn_adj, axis=-1))) # 24.18854748603352
print('sparsity', np.count_nonzero(sd_rn_adj) / (node_num**2) * 100) # 3.378288755032614